# -*- coding: utf-8 -*-
"""Scrapping.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QNijvodcYEBzyXpnMXVk6cYwbiZQ25dE
"""

import pandas as pd
import requests
from bs4 import BeautifulSoup

"""# **Scrapping du site sens-critique**

"""

url='https://www.senscritique.com/films/tops/top100-des-top10'

"""## **Obtenir les titres**"""

def get_title(link):
    html = requests.get(url)
    soup = BeautifulSoup(html.text)
    all_title=[]
    all_title_div = soup.find_all("h2", { "class" : "d-heading2 elco-title"})
    for liste in all_title_div:
        title=(liste.a.text)
        all_title.append(title)
    return all_title

all_title=get_title(url)

"""## **Obtenir les réalisateur**"""

def get_director(link):
    all_director=[]
    html = requests.get(url)
    soup = BeautifulSoup(html.text)
    all_direc_div = soup.find_all("p", { "class" : "elco-baseline"})
    for director_l in all_direc_div:
        director=(director_l.span.text)
        all_director.append(director)
               
    return all_director

all_director=get_director(url)

all_director = [elt for idx, elt in enumerate(all_director) if idx % 2 != 0]

"""## **Obtenir les liens des films**"""

def get_link_film(link):
    all_link_f=[]
    html = requests.get(link)
    soup = BeautifulSoup(html.text)
    all_link_f_div = soup.find_all("h2", { "class" : "d-heading2 elco-title"})
    for link_f in all_link_f_div:
        link=(link_f.a["href"])
        all_link_f.append(link)
    all_url_f=[]
    i=0
    while i < len(all_link_f):
        all_url_f.append("https://www.senscritique.com"+all_link_f[i])
        i+=1
      
    return all_url_f

all_url_f=get_link_film(url)

"""## **Obtenir les notes**"""

def get_rate(link):
    all_rate=[]
    for links in link:
        html = requests.get(links)
        soup = BeautifulSoup(html.text)
       
        all_rate_div = soup.find_all("div", { "class" : "pvi-product-scrating"})
        for rate_l in all_rate_div:
            rate=(rate_l.span.text)
            all_rate.append(rate)
               
    return all_rate

all_rate=get_rate(all_url_f)

for i in range(0,len(all_rate)):
  all_rate[i]=float(all_rate[i])

print(all_rate)

"""## **Obtenir les genres**"""

def get_genres(link):
    all_genres=[]
    for links in link:
        html = requests.get(links)
        soup = BeautifulSoup(html.text)
        all_genre_div = soup.find_all("a", { "class" : "lahe-breadcrumb-anchor"})[2].text
        all_genres.append(all_genre_div) 
        
    return all_genres

all_genres=get_genres(all_url_f)

"""## **Obtenir les dates de sortie**"""

def get_date(link):
    all_date=[]
    for links in link:
        html = requests.get(links)
        soup = BeautifulSoup(html.text)
        all_date_div = soup.find("small", { "class" : "pvi-product-year"}).text
        all_date_div=str(all_date_div)[1:-1]
        all_date.append(all_date_div) 
        
    return all_date

all_date=get_date(all_url_f)

"""## **Obtenir les acteurs**"""

def get_actors(link):
    all_actor_f=[]
    for links in link:
        all_actor=[]
        html = requests.get(links)
        soup = BeautifulSoup(html.text)
        all_actor_div1 = soup.find_all("span", { "class" : "d-offset ecot-contact-label"})[0].text
        all_actor_div2 = soup.find_all("span", { "class" : "d-offset ecot-contact-label"})[1].text
        all_actor_div3 = soup.find_all("span", { "class" : "d-offset ecot-contact-label"})[2].text
        all_actor.append(all_actor_div1)
        all_actor.append(all_actor_div2) 
        all_actor.append(all_actor_div3)
        all_actor_f.append(all_actor)
       
    return all_actor_f

all_actor=get_actors(all_url_f)

"""## **Obtenir la durée des film**"""

def get_duree(link):
    all_duree=[]
    for links in link:
        html = requests.get(links)
        soup = BeautifulSoup(html.text)
        all_duree_div = soup.find_all("li", { "class" : "pvi-productDetails-item"})[2].text[7:-9]
        all_duree.append(all_duree_div)
       
    return all_duree

all_duree=get_duree(all_url_f)

"""## **Obtenir la description**"""

def get_description(link):
    all_des=[]
    for links in link:
        html = requests.get(links)
        soup = BeautifulSoup(html.text)
        all_des_div = soup.find("p", { "class" : "pvi-productDetails-resume"}).text[5:-24]
        all_des.append(all_des_div)
        
    return all_des

all_description=get_description(all_url_f)

"""## **Création du dataset**"""

df_2 = pd.DataFrame({"titre": all_title, "date": all_date,"rate":all_rate, "lien":all_url_f,"réalisateur":all_director,"genres":all_genres,"durée":all_duree,"acteur":all_actor,"description":all_description})

df_2

"""## **Visualisation**"""

import plotly.express as px

print(px.colors.qualitative.G10)
print(px.colors.qualitative.Pastel1)
print(px.colors.qualitative.Prism)
print(px.colors.qualitative.Alphabet)

import plotly.express as px
data = px.data.gapminder()


fig = px.bar(df_2, x=df_2["genres"].value_counts().index, y=df_2["genres"].value_counts().values,
             color=['#3366CC', '#DC3912', '#FF9900', '#109618', '#990099', '#0099C6', '#DD4477', '#66AA00', '#B82E2E', '#316395','rgb(251,180,174)', 'rgb(179,205,227)', 'rgb(204,235,197)', 'rgb(222,203,228)', 'rgb(254,217,166)', 'rgb(255,255,204)', 'rgb(229,216,189)', 'rgb(253,218,236)', 'rgb(242,242,242)','rgb(95, 70, 144)']
             )
fig.update_layout(title_text='Genres')
fig.show()

import plotly.express as px
# This dataframe has 244 lines, but 4 distinct values for `day`

fig = px.pie(df_2, values=df_2['genres'].value_counts(), names=df_2["genres"].value_counts().index,color_discrete_sequence=px.colors.sequential.Plasma_r)
fig.update_layout(title_text='Pourcentage de chaque genres')
fig.show()

import plotly.express as px
data = px.data.gapminder()


fig = px.bar(df_2, x=df_2["réalisateur"].value_counts().index, y=df_2["réalisateur"].value_counts().values,
          color= df_2["réalisateur"].value_counts().index
             )
fig.update_layout(title_text='Réalisateur')
fig.show()

list_all_actor_value=[]
for i in range(0,100):
  for j in range(0,3):
    c=df_2["acteur"][i][j]
    list_all_actor_value.append(c)

df_actor_2 = pd.DataFrame({"acteur": list_all_actor_value})

nbr_actor_values=[]
nbr_actor_index=[]
for i in range(0,100):
    c=df_actor_2["acteur"].value_counts().values[i]
    j=df_actor_2["acteur"].value_counts().index[i]

    if c > 1:
      nbr_actor_values.append(c)
      nbr_actor_index.append(j)

import plotly.express as px
data = px.data.gapminder()


fig = px.bar(df_2, x=nbr_actor_index, y=nbr_actor_values,
            color=nbr_actor_index
             
             )
fig.update_layout(title_text='Acteur famous')
fig.show()

import plotly.express as px
fig = px.scatter(df_2, x=df_2["date"], y=df_2["rate"],color=df_2["titre"])
fig.update_layout(title_text='Classement des films en fonction des dates de sortie et de leur notes')
fig.show()

"""# **Scrapping du site imdb**"""

url='https://www.imdb.com/chart/top?pf_rd_m=A2FGELUUNOQJNL&pf_rd_p=4da9d9a5-d299-43f2-9c53-f0efa18182cd&pf_rd_r=DXK1EZW4ERJKM9CNKEVD&pf_rd_s=right-4&pf_rd_t=15506&pf_rd_i=moviemeter&ref_=chtmvm_ql_3'

"""## **Obtenir les titres**

"""

def get_title(link):
    html = requests.get(url)
    soup = BeautifulSoup(html.text)
    all_title=[]
    all_title_div = soup.find_all("td", { "class" : "titleColumn"})
    for liste in all_title_div:
        title=(liste.a.text)
        all_title.append(title)
    return all_title

all_title=get_title(url)

all_title=all_title[:100]

len(all_title)

"""## **Obtenir les dates**"""

def get_date(link):
    html = requests.get(url)
    soup = BeautifulSoup(html.text)
    all_date=[]
    all_date_div = soup.find_all("td", { "class" : "titleColumn"})
    for date_l in all_date_div:
        date=(date_l.span.text)
        all_date.append(date)
    return all_date

all_date=get_date(url)

all_date=all_date[:100]

len(all_date)

"""## **Obtenir les notes**"""

def get_rate(link):
    html = requests.get(url)
    soup = BeautifulSoup(html.text)
    all_rate=[]
    all_rate_div = soup.find_all("td", { "class" : "ratingColumn imdbRating"})
    for rate_l in all_rate_div:
        rate=(rate_l.strong.text)
        all_rate.append(rate)
    return all_rate

all_rate=get_rate(url)

all_rate=all_rate[:100]

"""## **Obtenir tous les liens des films**"""

def get_link(link):
    html = requests.get(url)
    soup = BeautifulSoup(html.text)
    all_link=[]
    all_link_div = soup.find_all("td", { "class" : "titleColumn"})
    for link_l in all_link_div:
        link=(link_l.a["href"])
        all_link.append(link)
    all_link=all_link[:100]
    all_url=[]
    i=0
    while i < len(all_link):
        all_url.append("https://www.imdb.com"+all_link[i])
        i+=1

    return all_url

all_url=get_link(url)

len(all_url)

"""## **Obtenir tous les réalisateur**"""

def get_director(link):
    all_director=[]
    for links in link:
        html = requests.get(links)
        soup = BeautifulSoup(html.text)
       
        all_direc_div = soup.find_all("a", { "class" : "ipc-metadata-list-item__list-content-item ipc-metadata-list-item__list-content-item--link"})[0].text
        all_director.append(all_direc_div)
        
    return all_director

all_director=get_director(all_url)

len(all_director)

"""## **Obtenir tous les genres**"""

def get_genres(link):
    all_genres=[]
    for links in link:
        html = requests.get(links)
        soup = BeautifulSoup(html.text)
        all_genre_div = soup.find_all("span", { "class" : "ipc-chip__text"})[0].text
       
        all_genres.append(all_genre_div)
        
    return all_genres

all_genres=get_genres(all_url)

len(all_genres)

"""## **Obtenir le budget**"""

pip install scrapy

def get_budget(link):
    from scrapy import Selector
    all_budget=[]
    for links in link:
        res = requests.get(links)
        sel = Selector(res)
        budget = ' '.join(sel.css(".txt-block:contains('Budget')::text").extract()).strip()
        all_budget.append(budget)
    return all_budget

all_budget=get_budget(all_url)

len(all_budget)

"""## **Obtenir la durée des films**"""

def get_time(link):
    import re
    all_time=[]
    for links in link:
        html = requests.get(links)
        soup = BeautifulSoup(html.text)
        all_time_div = soup.find_all("li",{"class":"ipc-inline-list__item"})[2].text
        all_time.append(all_time_div)
        
    i=0
    all_time2=[]
    all_time3=[]
    while i < len(all_time):
        s=all_time[i]
        regex = re.compile(r'[\n\r\t]')
        s = regex.sub(" ", s)
        all_time2.append(s)
        j=all_time2[i].replace(" ","")
        all_time3.append(j)
        i+=1        
    return all_time3

all_time=get_time(all_url)

len(all_time)

"""## **Obtenir tous les acteurs principaux**"""

def get_actors(link):
    all_actor_f=[]
    for links in link:
        all_actor=[]
        html = requests.get(links)
        soup = BeautifulSoup(html.text)
        all_actor_div1 = soup.find_all("a", { "class" : "ipc-metadata-list-item__list-content-item ipc-metadata-list-item__list-content-item--link"})[3].text
        all_actor_div2 = soup.find_all("a", { "class" : "ipc-metadata-list-item__list-content-item ipc-metadata-list-item__list-content-item--link"})[4].text
        all_actor_div3 = soup.find_all("a", { "class" : "ipc-metadata-list-item__list-content-item ipc-metadata-list-item__list-content-item--link"})[5].text
        all_actor.append(all_actor_div1)
        all_actor.append(all_actor_div2) 
        all_actor.append(all_actor_div3)
        all_actor_f.append(all_actor)
        
       
    return all_actor_f

all_actor=get_actors(all_url)

len(all_actor)

"""## **Obtenir les description**"""

def get_des(link):
    all_des=[]
    for links in link:
        html = requests.get(links)
        soup = BeautifulSoup(html.text)
        all_des_div = soup.find_all("div", { "class" : "GenresAndPlot__TextContainerBreakpointM-cum89p-2 iJnWgZ"})
        for liste_des in all_des_div:
                des=(liste_des.text)
                all_des.append(des)
                
    return all_des

all_des=get_des(all_url)

len(all_des)

"""## **Création du dataset**"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.DataFrame({"titre": all_title, "date": all_date,"rate":all_rate, "lien":all_url,"réalisateur":all_director,"genres":all_genres,"durée":all_time,"acteur":all_actor,"budget":all_budget,"description":all_des})

df

"""## **Visualisation**"""

classement=[]
i=100
while i>0:
    classement.append(i)
    i-=1
classement
df["classement"]=classement

group=df.groupby(["genres"]).agg(
    Classement=("classement","sum"))

group

group=group.sort_values(['Classement'], axis = 0, ascending = False)

import plotly.express as px
data = px.data.gapminder()


fig = px.bar(group, x=group["Classement"].index, y=group["Classement"].values,
             color=['antiquewhite', 'pink', 'aquamarine', 'green', 'red','aqua','blue','grey','yellow','black'],
             )
fig.update_layout(title_text='Popularité des genres')
fig.show()

import plotly.express as px
data = px.data.gapminder()


fig = px.bar(df, x=df["genres"].value_counts().index, y=df["genres"].value_counts().values,
             color=['blue', 'antiquewhite', 'aqua', 'aquamarine', 'red','green','pink','yellow','black','grey'],
             )
fig.update_layout(title_text='Genres')
fig.show()

import plotly.express as px
# This dataframe has 244 lines, but 4 distinct values for `day`

fig = px.pie(df, values=df['genres'].value_counts(), names=df["genres"].value_counts().index,color_discrete_sequence=px.colors.sequential.RdBu)
fig.update_layout(title_text='Pourcentage de chaque genres')
fig.show()

import plotly.express as px
data = px.data.gapminder()


fig = px.bar(df, x=df["réalisateur"].value_counts().index, y=df["réalisateur"].value_counts().values,
            color_discrete_sequence=px.colors.sequential.RdBu
             
             )
fig.update_layout(title_text='Réalisateur')
fig.show()

list_all_actor_value=[]
for i in range(0,100):
  for j in range(0,3):
    c=df["acteur"][i][j]
    list_all_actor_value.append(c)

df_actor = pd.DataFrame({"acteur": list_all_actor_value})

nbr_actor_values=[]
nbr_actor_index=[]
for i in range(0,100):
    c=df_actor["acteur"].value_counts().values[i]
    j=df_actor["acteur"].value_counts().index[i]

    if c > 1:
      nbr_actor_values.append(c)
      nbr_actor_index.append(j)

import plotly.express as px
data = px.data.gapminder()


fig = px.bar(df, x=nbr_actor_index, y=nbr_actor_values,
            color=nbr_actor_index
             
             )
fig.update_layout(title_text='Acteur famous')
fig.show()

df["réalisateur"].value_counts().idxmax()

df["durée"][14]='2h04min'
df["durée"][24]='2h01min'
df["durée"][26]='2h05min'
df["durée"][19]='2h07min'
df["durée"][27]='3h09min'
df["durée"][55]='2h05min'
df["durée"][62]='2h02min'
df["durée"][69]='2h00min'
df["durée"][76]='2h06min'
df["durée"][77]='3h01min'
df["durée"][79]='2h02min'
df["durée"][85]='2h06min'
df["durée"][92]='2h08min'
df["durée"][78]='3h01min'
df["durée"][68]='2h00min'
df["durée"][75]='2h00min'

listmin=[]
i=0
while i < len(df["durée"]):
  g=df["durée"][i]

  t=g[0]
  t=int(t)
  f=g[2:4]
  f=int(f)
  final=t*60+f
  listmin.append(final)
  i+=1

df["durée_min"]=listmin

# avg. transaction amount at each hour for each transaction type
plt.figure(figsize=(18,6))
sns.lineplot(data=df.groupby(['rate','genres']).agg({'durée_min' : 'mean'}).round(2).reset_index(),
             x='rate',
             y='durée_min',
             hue='genres')
plt.xlabel('Rate', fontsize=15, fontweight='bold')
plt.xticks(range(11), range(11),fontsize=15, fontweight='bold', rotation=0)
plt.ylabel('Moy durée en min', fontsize=15, fontweight='bold')
plt.yticks(fontsize=15, fontweight='bold')
plt.title('Moy durée en min en fonction de la note', fontsize=22, fontweight='bold')
plt.show()

# x and y given as DataFrame columns
import plotly.express as px
fig = px.scatter(df, x=df["date"], y=df["rate"],color=df["titre"])
fig.update_layout(title_text='Classement des films en fonction des dates de sortie et de leur notes')
fig.show()

import plotly.graph_objects as go
fig = go.Figure(data=[
    go.Bar( name='imdb',x=df["genres"].value_counts().index, y=df["genres"].value_counts().values),
    go.Bar(name='sens critique',x=df_2["genres"].value_counts().index, y=df_2["genres"].value_counts().values)
])
# Change the bar mode
fig.update_layout(barmode='group')
fig.show()

